{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PAqRQDkzST5"
      },
      "source": [
        "## Part-of-Speech Tagging using Hidden Markov Model (HMM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1dE99WHwcYq"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import treebank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwLMdpMIwhgk",
        "outputId": "42816a78-11ef-4258-8ca5-a06d34feb635"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download treebank dataset\n",
        "nltk.download('treebank')\n",
        "nltk.download('universal_tagset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ux6hshZBxJF0"
      },
      "outputs": [],
      "source": [
        "def train_hmm(corpus):\n",
        "    # Initialize dictionaries for counts\n",
        "    tag_counts = defaultdict(int)\n",
        "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
        "    emission_counts = defaultdict(lambda: defaultdict(int))\n",
        "    vocab = set()\n",
        "\n",
        "    # Process corpus with universal tagset\n",
        "    for sentence in corpus:\n",
        "        prev_tag = '<START>'\n",
        "        tag_counts['<START>'] += 1\n",
        "        for word, tag in sentence:\n",
        "            word = word.lower()\n",
        "            tag_counts[tag] += 1\n",
        "            transition_counts[prev_tag][tag] += 1\n",
        "            emission_counts[tag][word] += 1\n",
        "            vocab.add(word)\n",
        "            prev_tag = tag\n",
        "        transition_counts[prev_tag]['<END>'] += 1\n",
        "        tag_counts['<END>'] += 1\n",
        "\n",
        "    # Compute probabilities with add-one smoothing\n",
        "    tags = list(tag_counts.keys())\n",
        "    vocab_size = len(vocab)\n",
        "    transition_probs = defaultdict(lambda: defaultdict(float))\n",
        "    emission_probs = defaultdict(lambda: defaultdict(float))\n",
        "\n",
        "    for tag in tags:\n",
        "        # Transition probabilities\n",
        "        total_trans = sum(transition_counts[tag].values())\n",
        "        for next_tag in tags:\n",
        "            transition_probs[tag][next_tag] = (transition_counts[tag][next_tag] + 1) / (total_trans + len(tags))\n",
        "\n",
        "        # Emission probabilities with <UNK> handling\n",
        "        total_emissions = sum(emission_counts[tag].values())\n",
        "        for word in vocab:\n",
        "            emission_probs[tag][word] = (emission_counts[tag][word] + 1) / (total_emissions + vocab_size + 1)\n",
        "        emission_probs[tag][\"<UNK>\"] = 1 / (total_emissions + vocab_size + 1)\n",
        "\n",
        "    return tags, vocab, transition_probs, emission_probs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lC_j-rExO0m"
      },
      "outputs": [],
      "source": [
        "def viterbi(sentence, tags, vocab, transition_probs, emission_probs):\n",
        "    V = [{}]\n",
        "    path = {}\n",
        "\n",
        "    # Initialize with start state\n",
        "    for tag in tags:\n",
        "        if tag not in {'<START>', '<END>'}:\n",
        "            word = sentence[0].lower()\n",
        "            emission = emission_probs[tag].get(word, emission_probs[tag][\"<UNK>\"])\n",
        "            V[0][tag] = np.log(transition_probs['<START>'][tag]) + np.log(emission)\n",
        "            path[tag] = [tag]\n",
        "\n",
        "    # Run Viterbi\n",
        "    for t in range(1, len(sentence)):\n",
        "        V.append({})\n",
        "        new_path = {}\n",
        "        word = sentence[t].lower()\n",
        "        for curr_tag in tags:\n",
        "            if curr_tag not in {'<START>', '<END>'}:\n",
        "                emission = emission_probs[curr_tag].get(word, emission_probs[curr_tag][\"<UNK>\"])\n",
        "                max_prob, best_prev_tag = max(\n",
        "                    (V[t-1][prev_tag] + np.log(transition_probs[prev_tag][curr_tag]) + np.log(emission), prev_tag)\n",
        "                    for prev_tag in tags if prev_tag not in {'<START>', '<END>'}\n",
        "                )\n",
        "                V[t][curr_tag] = max_prob\n",
        "                new_path[curr_tag] = path[best_prev_tag] + [curr_tag]\n",
        "        path = new_path\n",
        "\n",
        "    # Termination\n",
        "    max_prob, best_tag = max(\n",
        "        (V[-1][tag] + np.log(transition_probs[tag]['<END>']), tag)\n",
        "        for tag in tags if tag not in {'<START>', '<END>'}\n",
        "    )\n",
        "    return path[best_tag], max_prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBfr5ntAxRV2"
      },
      "outputs": [],
      "source": [
        "def evaluate_hmm(test_corpus, tags, vocab, transition_probs, emission_probs):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for sentence in test_corpus:\n",
        "        words = [word for word, _ in sentence]\n",
        "        true_tags = [tag for _, tag in sentence]\n",
        "        predicted_tags, _ = viterbi(words, tags, vocab, transition_probs, emission_probs)\n",
        "        correct += sum(1 for true, pred in zip(true_tags, predicted_tags) if true == pred)\n",
        "        total += len(true_tags)\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDvuXGNLxS9S"
      },
      "outputs": [],
      "source": [
        "# Load data with universal tagset\n",
        "corpus = treebank.tagged_sents(tagset='universal')[:3000]  # Training\n",
        "test_corpus = treebank.tagged_sents(tagset='universal')[3000:3750]  # Testing\n",
        "\n",
        "# Train HMM\n",
        "tags, vocab, transition_probs, emission_probs = train_hmm(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArZB2RHvxVcu",
        "outputId": "c465b5d7-f334-47ab-d50b-e9d5bfc4b1b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Input: ['The', 'quick', 'brown', 'fox', 'jumps']\n",
            "Predicted Tags: ['DET', 'ADJ', 'NOUN', 'NOUN', '.']\n"
          ]
        }
      ],
      "source": [
        "# Sample input/output\n",
        "sample_sentence = [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\"]\n",
        "predicted_tags, prob = viterbi(sample_sentence, tags, vocab, transition_probs, emission_probs)\n",
        "print(\"Sample Input:\", sample_sentence)\n",
        "print(\"Predicted Tags:\", predicted_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PONCFkSRxa05",
        "outputId": "e9765050-2104-42a9-cd5e-379914d69b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8832\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "accuracy = evaluate_hmm(test_corpus, tags, vocab, transition_probs, emission_probs)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
