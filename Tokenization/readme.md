# ğŸ§  Tokenization Techniques in NLP

This project explores various tokenization techniques, including basic implementations, NLTK, spaCy, and subword tokenization using BERT-based tokenizers.

## ğŸ“Œ Objectives

- Implement basic tokenizers using Python.
- Compare tokenization approaches from different libraries: NLTK, spaCy, HuggingFace.
- Understand how preprocessing affects tokenization (e.g., punctuation, casing).
- Explore subword tokenization using Byte Pair Encoding (BPE).

---

## ğŸ§ª Sample Text Used

```
"Tokenization is the first step in NLP. It involves splitting text into meaningful units."
```

---

## 1ï¸âƒ£ Basic Tokenization (Custom Python)

- **Whitespace Tokenization**: Uses `str.split()`
- **Regex Tokenization**: Uses `re.split()` to split on punctuation.

### ğŸ” Insights

- Whitespace tokenizer is naive â€” cannot handle punctuation or contractions.
- Regex-based tokenization improves by removing punctuations and special chars.

---

## 2ï¸âƒ£ Tokenization with NLTK

- **Word Tokenization**: `nltk.word_tokenize()`
- **Sentence Tokenization**: `nltk.sent_tokenize()`

### ğŸ” Observations

- Handles punctuation and quotes well.
- Tokenizes contractions and possessives properly.
- Requires downloading `punkt`.

---

## 3ï¸âƒ£ Tokenization with spaCy

- **Model**: `en_core_web_sm`
- Automatically handles:
  - Punctuation
  - Lemmatization
  - Special characters

### ğŸ›  Preprocessing

- Implemented stopword removal and lowercasing.
- SpaCy offers better consistency across sentence structures.

---

## 4ï¸âƒ£ Subword Tokenization (BPE - Byte Pair Encoding)

- **Model**: `bert-base-uncased` from HuggingFace
- **Tokenizer**: `AutoTokenizer`

### ğŸ” BPE Tokenization Example

```python
['tokenization', 'is', 'an', 'essential', 'part', 'of', 'nl', '##p', '.']
```

- Splits unknown or rare words into subwords (e.g., `nlp` â†’ `nl`, `##p`)
- Excellent for generalization and transfer learning

---

## ğŸ§¾ Summary

| Method       | Handles Punctuation | Case Norm | Subwords | Pre-Trained |
|--------------|---------------------|-----------|----------|-------------|
| Whitespace   | âŒ                  | âŒ        | âŒ       | âŒ          |
| Regex        | âœ…                  | âŒ        | âŒ       | âŒ          |
| NLTK         | âœ…                  | âŒ        | âŒ       | âŒ          |
| spaCy        | âœ…                  | âœ…        | âŒ       | âœ…          |
| BERT (BPE)   | âœ…                  | âœ…        | âœ…       | âœ…          |

---

## ğŸ“š Requirements

```bash
pip install nltk spacy transformers sentencepiece
python -m spacy download en_core_web_sm
```

---

